{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "overall.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmowq9giFRXL"
      },
      "source": [
        "# Support for TF2 models was added after TF 2.3.\n",
        "!pip install tf-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM2RIJk3WLtw"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jiNTpZWWOj_"
      },
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEw4X-6FWXvl"
      },
      "source": [
        "# Download the checkpoint and put it into models/research/object_detection/test_data/\n",
        "\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
        "!tar -xf ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so0GSnHrXUnB"
      },
      "source": [
        "#https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_graph_tf2.py\n",
        "%%bash\n",
        "python models/research/object_detection/export_tflite_graph_tf2.py \\\n",
        "  --pipeline_config_path /content/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config \\\n",
        "  --trained_checkpoint_dir /content/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint \\\n",
        "  --output_directory /content/tflite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyJTVm5RXo3J"
      },
      "source": [
        "!tflite_convert --saved_model_dir=tflite/saved_model --output_file=tflite/model.tflite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqPUA2FmZSTJ"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('tflite/model.tflite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwxDCUU1MNu-"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njsoM4t1Zktz"
      },
      "source": [
        "# Tflite model: dynamic range quantization\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('tflite/saved_model')\n",
        "converter.experimental_new_converter = False\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_model_dynamic = converter.convert()\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"tflite\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Save the model:\n",
        "tflite_model_file = tflite_models_dir/\"dynamic_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model_dynamic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6zZ4XKHcUW-"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('tflite/dynamic_model.tflite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR7b3Ib8c25L"
      },
      "source": [
        "# Tflite model: float 16 quantization\n",
        "# For debugging\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('tflite/saved_model')\n",
        "converter.experimental_new_converter = False\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "tflite_model_16_float = converter.convert()\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"tflite\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Save the model:\n",
        "tflite_model_file = tflite_models_dir/\"16_float.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model_16_float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY7ICoEyd73g"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('tflite/16_float.tflite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSsa_vI7Mu5m"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wQb1uknd-qB"
      },
      "source": [
        "# Tflite model: integer only quantization\n",
        "# For debugging\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "num_calibration_images = 100\n",
        "\n",
        "# Random representative data\n",
        "def representative_data_gen():\n",
        "  for _ in range(num_calibration_images):\n",
        "    image = np.random.randint(low=0, high=255, size=(1, 640, 640, 3))\n",
        "    image = image.astype(np.float32)\n",
        "    yield [image]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('tflite/saved_model')\n",
        "converter.experimental_new_converter = False\n",
        "converter.allow_custom_ops = True\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "# Ensure that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "tflite_model_int_rep_random = converter.convert()\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"tflite\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Save the model:\n",
        "tflite_model_file = tflite_models_dir/\"8_int_model_rep_random.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model_int_rep_random)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gqEv8vmeIej"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"tflite/8_int_model_rep_random.tflite\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qla40yQzecdN"
      },
      "source": [
        "# Tflite model: integer only quantization\n",
        "# For debugging\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('tflite/saved_model')\n",
        "converter.experimental_new_converter = False\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_model_int_rep_random = converter.convert()\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"tflite\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Save the model:\n",
        "tflite_model_file = tflite_models_dir/\"default.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model_int_rep_random)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nydVLgaRTeZy"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"tflite/default.tflite\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_PoX1GDTz9U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}